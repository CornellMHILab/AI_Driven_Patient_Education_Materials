{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# read the excel file\n",
    "df = pd.read_excel(\"Articles with Rules.xlsx\", usecols = [1,2])\n",
    "# limit dataframe to the first two columns (url and term)\n",
    "df = df[1:-1]\n",
    "# exclude unknown data from the dataframe\n",
    "df = df.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Following contains scraped data from healthline and eatingwell (notify the method can measure scraped data less than 4096 tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# refine the data frame which only contains healthline\n",
    "df1 = df[df['URL'].str.contains('healthline')]\n",
    "# refine the data frame which only contains eatingwell\n",
    "df2 = df[df['URL'].str.contains('eatingwell')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   url  \\\n9    https://www.healthline.com/health/pregnancy/no...   \n28   https://www.healthline.com/health/pregnancy/di...   \n42   https://www.healthline.com/health/pregnancy/po...   \n43   https://www.healthline.com/health/pregnancy/nu...   \n44   https://www.healthline.com/nutrition/13-foods-...   \n45   https://www.healthline.com/health/pregnancy/be...   \n46   https://www.healthline.com/health/pregnancy/se...   \n47   https://www.healthline.com/health/postpartum-diet   \n48   https://www.healthline.com/health-news/eating-...   \n49   https://www.healthline.com/nutrition/supplemen...   \n132  https://www.healthline.com/health/depression/h...   \n256  https://www.healthline.com/health/postpartum-d...   \n266  https://www.healthline.com/health/pregnancy/po...   \n267  https://www.healthline.com/health/depression/h...   \n\n                                                 title  \\\n9    7 Soups to Replenish and Rejuvenate the Postpa...   \n28                       Healthy Diet During Pregnancy   \n42                  11 Best Postnatal Vitamins of 2023   \n43                  Nutritional Needs During Pregnancy   \n44                13 Foods to Eat When You're Pregnant   \n45   Fruits to Eat During Pregnancy: Nutritious Opt...   \n46   Second Trimester Diet: Daily Requirements, Cra...   \n47   Postpartum Diet Plan: Tips for Healthy Eating ...   \n48         Pregnancy Diet and Risk of Low Birth Weight   \n49   Supplements During Pregnancy: What’s Safe and ...   \n132  How to Deal with Postpartum Depression: Diet, ...   \n256  How to Get Postpartum Depression Treatment wit...   \n266  Postnatal Yoga: Benefits, Risks, and a Sample ...   \n267          How Long Does Postpartum Depression Last?   \n\n                                                  data  \n9    Share on PinterestBefore welcoming a new child...  \n28   Share on PinterestIf you’re concerned about wh...  \n42   Share on PinterestWe include products we think...  \n43   Share on PinterestAs you probably know, your b...  \n44   While you’re pregnant, you’ll want to eat extr...  \n45   Eating nutritious food is important for you an...  \n46   Share on PinterestCopyright: Dean MitchellWe i...  \n47   Share on PinterestIt’s no secret that the food...  \n48   Share on PinterestBoris Jovanovic/Stocksy Unit...  \n49   Share on PinterestIf you’re pregnant, you may ...  \n132  The period after you have your baby can be fil...  \n256  Share on PinterestPolina Strelkova / Getty Ima...  \n266  Share on PinterestGetty ImagesWhether you’ve j...  \n267  Share on PinterestIf pregnancy is an emotional...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>title</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>https://www.healthline.com/health/pregnancy/no...</td>\n      <td>7 Soups to Replenish and Rejuvenate the Postpa...</td>\n      <td>Share on PinterestBefore welcoming a new child...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>https://www.healthline.com/health/pregnancy/di...</td>\n      <td>Healthy Diet During Pregnancy</td>\n      <td>Share on PinterestIf you’re concerned about wh...</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>https://www.healthline.com/health/pregnancy/po...</td>\n      <td>11 Best Postnatal Vitamins of 2023</td>\n      <td>Share on PinterestWe include products we think...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>https://www.healthline.com/health/pregnancy/nu...</td>\n      <td>Nutritional Needs During Pregnancy</td>\n      <td>Share on PinterestAs you probably know, your b...</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>https://www.healthline.com/nutrition/13-foods-...</td>\n      <td>13 Foods to Eat When You're Pregnant</td>\n      <td>While you’re pregnant, you’ll want to eat extr...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>https://www.healthline.com/health/pregnancy/be...</td>\n      <td>Fruits to Eat During Pregnancy: Nutritious Opt...</td>\n      <td>Eating nutritious food is important for you an...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>https://www.healthline.com/health/pregnancy/se...</td>\n      <td>Second Trimester Diet: Daily Requirements, Cra...</td>\n      <td>Share on PinterestCopyright: Dean MitchellWe i...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>https://www.healthline.com/health/postpartum-diet</td>\n      <td>Postpartum Diet Plan: Tips for Healthy Eating ...</td>\n      <td>Share on PinterestIt’s no secret that the food...</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>https://www.healthline.com/health-news/eating-...</td>\n      <td>Pregnancy Diet and Risk of Low Birth Weight</td>\n      <td>Share on PinterestBoris Jovanovic/Stocksy Unit...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>https://www.healthline.com/nutrition/supplemen...</td>\n      <td>Supplements During Pregnancy: What’s Safe and ...</td>\n      <td>Share on PinterestIf you’re pregnant, you may ...</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>https://www.healthline.com/health/depression/h...</td>\n      <td>How to Deal with Postpartum Depression: Diet, ...</td>\n      <td>The period after you have your baby can be fil...</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>https://www.healthline.com/health/postpartum-d...</td>\n      <td>How to Get Postpartum Depression Treatment wit...</td>\n      <td>Share on PinterestPolina Strelkova / Getty Ima...</td>\n    </tr>\n    <tr>\n      <th>266</th>\n      <td>https://www.healthline.com/health/pregnancy/po...</td>\n      <td>Postnatal Yoga: Benefits, Risks, and a Sample ...</td>\n      <td>Share on PinterestGetty ImagesWhether you’ve j...</td>\n    </tr>\n    <tr>\n      <th>267</th>\n      <td>https://www.healthline.com/health/depression/h...</td>\n      <td>How Long Does Postpartum Depression Last?</td>\n      <td>Share on PinterestIf pregnancy is an emotional...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrape information from url in the dataframe for healthline\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# set up a header to inform website to avoid 418 error (you will need to change this setting)\n",
    "headers = {\"User-Agent\":'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'}\n",
    "results_healthline = []\n",
    "title_healthline = []\n",
    "for url in df1['URL']:\n",
    "    response = requests.get(url, headers = headers).text\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    # find the section of the page that contains the article text\n",
    "    article_section = soup.find('article', {'class': 'article-body css-d2znx6 undefined'})\n",
    "    title_section = soup.find('title')\n",
    "    # extract the text content of the article\n",
    "    article_text = article_section.text.strip()\n",
    "    title_text = title_section.text.strip()\n",
    "\n",
    "    results_healthline.append(article_text)\n",
    "    title_healthline.append(title_text)\n",
    "\n",
    "# set up dataframe to store information\n",
    "df_results1 = pd.DataFrame({'url': df1['URL'], 'title': title_healthline,\n",
    "                            'data': results_healthline})\n",
    "df_results1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  url  \\\n33  https://www.eatingwell.com/article/290540/what...   \n34  https://www.eatingwell.com/article/7900675/top...   \n35  https://www.eatingwell.com/article/290541/what...   \n36  https://www.eatingwell.com/article/290598/what...   \n37  https://www.eatingwell.com/article/15660/healt...   \n38  https://www.eatingwell.com/article/290403/food...   \n\n                                                title  \\\n33  What to Eat When You're Pregnant: First Trimester   \n34  Top 10 Pregnancy Superfoods, According to Diet...   \n35  What to Eat When You're Pregnant: Second Trime...   \n36  What a Healthy Day of Pregnancy Eating Looks L...   \n37                                                NaN   \n38                         Foods for Morning Sickness   \n\n                                                 data  \n33  Welcome to the first trimester of pregnancy, c...  \n34  We independently evaluate all recommended prod...  \n35  Congratulations! You made it to the second tri...  \n36  It's the third trimester, and you're in the ho...  \n37                                                NaN  \n38  It could be a faint whiff of cilantro in a sal...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>title</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>https://www.eatingwell.com/article/290540/what...</td>\n      <td>What to Eat When You're Pregnant: First Trimester</td>\n      <td>Welcome to the first trimester of pregnancy, c...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>https://www.eatingwell.com/article/7900675/top...</td>\n      <td>Top 10 Pregnancy Superfoods, According to Diet...</td>\n      <td>We independently evaluate all recommended prod...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>https://www.eatingwell.com/article/290541/what...</td>\n      <td>What to Eat When You're Pregnant: Second Trime...</td>\n      <td>Congratulations! You made it to the second tri...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>https://www.eatingwell.com/article/290598/what...</td>\n      <td>What a Healthy Day of Pregnancy Eating Looks L...</td>\n      <td>It's the third trimester, and you're in the ho...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>https://www.eatingwell.com/article/15660/healt...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>https://www.eatingwell.com/article/290403/food...</td>\n      <td>Foods for Morning Sickness</td>\n      <td>It could be a faint whiff of cilantro in a sal...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrope information from url in the dataframe for eatingwell\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# setup a header to inform website to avoid 418 error\n",
    "headers = {\"User-Agent\":'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'}\n",
    "results_eatingwell = []\n",
    "title_eatingwell = []\n",
    "\n",
    "for url in df2['URL']:\n",
    "    try:\n",
    "        response = requests.get(url, headers = headers).text\n",
    "        soup = BeautifulSoup(response, 'html.parser')\n",
    "        # find the section of the page that contains the article text\n",
    "        article_section = soup.find('div', {'class': 'loc article-content'})\n",
    "\n",
    "        title_section = soup.find('title')\n",
    "        # Extract the text content of the article\n",
    "        article_text = article_section.text.strip()\n",
    "        results_eatingwell.append(article_text)\n",
    "        title_text = title_section.text.strip()\n",
    "        title_eatingwell.append(title_text)\n",
    "    except:\n",
    "        results_eatingwell.append(\"NaN\")\n",
    "        title_eatingwell.append('NaN')\n",
    "# set up dataframe to store information\n",
    "df_results2 = pd.DataFrame({'url': df2['URL'], 'title': title_eatingwell,\n",
    "                            'data': results_eatingwell})\n",
    "df_results2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# combine two dataframe into one\n",
    "df_final = pd.concat([df_results1,df_results2], axis = 0)\n",
    "df_final.to_csv('scraped_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import openai"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#enter your api key here\n",
    "openai.api_key =''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# write a function to reduce additional blanks\n",
    "def reduce_long_blanks(content):\n",
    "    sentences = sent_tokenize(content)\n",
    "    filtered_sentencess = [sentence for sentence in sentences if sentence.strip()]\n",
    "    summary = ' '.join(filtered_sentencess)\n",
    "    summary = summary.replace('\\n','')\n",
    "    summary = summary.replace('\\\\','')\n",
    "    return summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checking number of tokens of each scraped answer\n",
    "for i in range(len(df_final)):\n",
    "    re = reduce_long_blanks(df_final.iloc[i,2])\n",
    "    tokens = nltk.word_tokenize(re)\n",
    "    num_tokens = len(tokens)\n",
    "    print(\"number of tokens\", num_tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use this method if you notify that number of tokens exceed 4096\n",
    "summary = []\n",
    "import nltk\n",
    "\n",
    "# set up max number of tokens of each time getting response from chatgpt\n",
    "max = 2750\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    # get article title and content\n",
    "    article_title = df_final.iloc[i, 1]\n",
    "    article_content = df_final.iloc[i, 2]\n",
    "\n",
    "    # reduce blanks\n",
    "    reduced_content = reduce_long_blanks(article_content)\n",
    "    # tokenize the content\n",
    "    tokens = nltk.word_tokenize(reduced_content)\n",
    "\n",
    "    # check if tokens exceed max tokens\n",
    "    if len(tokens) > max:\n",
    "        # location offset of start token\n",
    "        start = 0\n",
    "        # trial number of separate response\n",
    "        count = 0\n",
    "        # sub-summary\n",
    "        small_summary = []\n",
    "        while start < len(tokens):\n",
    "            if count == 4:\n",
    "                break\n",
    "            chunk_tokens = tokens[start: start + max]\n",
    "            chunk_content = \" \".join(chunk_tokens)\n",
    "            scraped_data = \"content is \" + chunk_content\n",
    "            if count == 0:\n",
    "                prompt = \"Summarize this for me: \" + scraped_data + \". I will send the next part later.\"\n",
    "            elif count == 1:\n",
    "                prompt = \"Here is the second part for summarization\" + scraped_data\n",
    "            elif count == 2:\n",
    "                prompt = \"Here is the third part for summarization\" + scraped_data\n",
    "            else:\n",
    "                prompt = \"Here is the last part for summarization: \" + scraped_data\n",
    "            # get summary from GPT\n",
    "            response = openai.Completion.create(\n",
    "                engine='text-davinci-003',\n",
    "                prompt=prompt,\n",
    "                max_tokens=400,\n",
    "                temperature=0.3,\n",
    "                n=1,\n",
    "                stop=None,\n",
    "            )\n",
    "            res = response.choices[0].text.strip()\n",
    "            small_summary.append(res)\n",
    "            start += max\n",
    "            count += 1\n",
    "        # summarize again for all short summaries\n",
    "        small_summary_tostr = ' '.join(small_summary)\n",
    "\n",
    "        all_prompt = \"Summarize this for me: \" + small_summary_tostr\n",
    "        response = openai.Completion.create(\n",
    "            engine='text-davinci-003',\n",
    "            prompt=all_prompt,\n",
    "            max_tokens=400,\n",
    "            temperature=0.3,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "        )\n",
    "        res = response.choices[0].text.strip()\n",
    "        summary.append(res)\n",
    "    else:\n",
    "        # combine title and content\n",
    "        scraped_data = \"title is \" + article_title + \", and content is \" + reduced_content\n",
    "        prompt = \"Summarize this for me:\" + scraped_data\n",
    "\n",
    "        # get summary from GPT\n",
    "        response = openai.Completion.create(\n",
    "            engine='text-davinci-003',\n",
    "            prompt=prompt,\n",
    "            max_tokens=400,\n",
    "            temperature=0.3,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "        )\n",
    "        res = response.choices[0].text.strip()\n",
    "\n",
    "        summary.append(res)\n",
    "\n",
    "# create a dataframe for summaries\n",
    "df_summary = pd.DataFrame(summary, columns=[\"Summary\"])\n",
    "# drop off index of original dataframe\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "# combine dataframes\n",
    "df_gpt_summary = pd.concat([df_final, df_summary], ignore_index=True, axis=1)\n",
    "df_gpt_summary.columns = [\"Url\", \"Title\", \"Data\", \"Summary\"]\n",
    "df_gpt_summary.drop(columns = \"Data\", inplace = True)\n",
    "df_gpt_summary.to_excel('summary.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The following is scraped data from parents and romper (notify the method only measures scraped data less than 4096 tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df3 = df[df['URL'].str.contains('parents')]\n",
    "df4 = df[df['URL'].str.contains('romper')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\"User-Agent\":'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'}\n",
    "\n",
    "results_parents = []\n",
    "title_parents= []\n",
    "for url in df3['URL']:\n",
    "    response = requests.get(url, headers = headers).text\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    # Adjusting the classes to match the website's HTML structure\n",
    "    article_section = soup.find('div', {'class': 'loc article-content'})\n",
    "    title_section = soup.find('title')\n",
    "\n",
    "    if article_section and title_section:\n",
    "        # Extracting the text content of the article\n",
    "        article_text = article_section.text.strip()\n",
    "        title_text = title_section.text.strip()\n",
    "\n",
    "        results_parents.append(article_text)\n",
    "        title_parents.append(title_text)\n",
    "    else:\n",
    "        results_parents.append(\"None\")\n",
    "        title_parents.append(\"None\")\n",
    "\n",
    "# Set up DataFrame to store information\n",
    "df_results_parents = pd.DataFrame({\n",
    "    'url': df3['URL'],\n",
    "    'title': title_parents,\n",
    "    'data': results_parents\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\"User-Agent\":'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'}\n",
    "\n",
    "results_romper = []\n",
    "title_romper = []\n",
    "for url in df4['URL']:\n",
    "    response = requests.get(url, headers = headers).text\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    # Adjusting the classes to match the website's HTML structure\n",
    "    article_section = soup.find('div', {'class': 'AOL Afg'})\n",
    "    title_section = soup.find('title')\n",
    "\n",
    "    if article_section and title_section:\n",
    "        # Extracting the text content of the article\n",
    "        article_text = article_section.text.strip()\n",
    "        title_text = title_section.text.strip()\n",
    "\n",
    "        results_romper.append(article_text)\n",
    "        title_romper.append(title_text)\n",
    "    else:\n",
    "        results_romper.append(\"None\")\n",
    "        title_romper.append(\"None\")\n",
    "\n",
    "# Set up DataFrame to store information\n",
    "df_results_romper = pd.DataFrame({\n",
    "    'url': df4['URL'],\n",
    "    'title': title_romper,\n",
    "    'data': results_romper\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_final2 = pd.concat([df_results_parents, df_results_romper], axis=0)\n",
    "df_final2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checking number of tokens of each scraped answer\n",
    "for i in range(len(df_final2)):\n",
    "    re = reduce_long_blanks(df_final2.iloc[i, 2])\n",
    "    tokens = nltk.word_tokenize(re)\n",
    "    num_tokens = len(tokens)\n",
    "    if num_tokens >= 2750:\n",
    "        print(\"number of tokens\", num_tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "import nltk\n",
    "summary=[]\n",
    "for i in range(len(df_final2)):\n",
    "    # get article title and content\n",
    "    article_title = df_final2.iloc[i,1]\n",
    "    article_content = df_final2.iloc[i,2]\n",
    "\n",
    "    # reduce blanks\n",
    "    reduced_content = reduce_long_blanks(article_content)\n",
    "    # tokenize the content\n",
    "    tokens = nltk.word_tokenize(reduced_content)\n",
    "    # combine title and content\n",
    "    scraped_data = \"title is \" + article_title +\", and content is \" + reduced_content\n",
    "    prompt = \"Summarize this for me:\" + scraped_data\n",
    "\n",
    "    # get summary from GPT\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=400,\n",
    "        temperature=0.3,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "    )\n",
    "    res = response.choices[0].text.strip()\n",
    "\n",
    "    summary.append(res)\n",
    "\n",
    "df_summary2 = pd.DataFrame(summary, columns=[\"Summary\"])\n",
    "# drop off index of original dataframe\n",
    "df_final2 = df_final2.reset_index(drop=True)\n",
    "# combine dataframes\n",
    "df_gpt_summary2 = pd.concat([df_final2, df_summary2], ignore_index=True, axis=1)\n",
    "df_gpt_summary2.columns = [\"Url\", \"Title\", \"Data\", \"Summary\"]\n",
    "df_gpt_summary2.drop(columns = \"Data\", inplace = True)\n",
    "df_gpt_summary2.to_excel('summary2.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
